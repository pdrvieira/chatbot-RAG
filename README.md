# Chat RAG para Petshop ğŸ¾

Chat inteligente que responde perguntas sobre um petshop usando RAG (Retrieval Augmented Generation). O sistema busca informaÃ§Ãµes relevantes no banco de dados e gera respostas contextualizadas com LLM.

## ğŸ› ï¸ Tecnologias

### Backend
- **FastAPI** - Framework web
- **SQLAlchemy** - ORM para SQLite
- **SQLite** - Banco de dados
- **Sentence Transformers** - Modelo BGE-small para embeddings
- **LangChain** - IntegraÃ§Ã£o com LLMs
- **DeepSeek R1** - LLM via OpenRouter
- **Pytest** - Testes

### Frontend
- **React** - Biblioteca UI
- **TypeScript** - Tipagem estÃ¡tica
- **Vite** - Build tool
- **CSS Modules** - EstilizaÃ§Ã£o

## ğŸ§  Como Funciona o RAG

1. **UsuÃ¡rio faz uma pergunta** no chat
2. **Backend gera embedding da pergunta** usando BGE-small
3. **Busca documentos similares** no banco (cÃ¡lculo de similaridade cosseno)
4. **Seleciona os top-3 documentos** mais relevantes
5. **Monta um contexto** juntando os documentos
6. **Envia para o LLM** (DeepSeek R1) com o contexto
7. **Retorna a resposta** para o frontend com as fontes usadas

```
Pergunta â†’ Embedding â†’ Busca Vetorial â†’ Contexto â†’ LLM â†’ Resposta
```

## ğŸ“ Estrutura do Projeto

```
chatbot-RAG/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py           # entrada da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ database.py       # configuraÃ§Ã£o SQLite
â”‚   â”‚   â”œâ”€â”€ models.py         # modelo Document
â”‚   â”‚   â”œâ”€â”€ schemas.py        # schemas Pydantic
â”‚   â”‚   â”œâ”€â”€ embeddings.py     # BGE-small + similaridade
â”‚   â”‚   â”œâ”€â”€ llm.py            # integraÃ§Ã£o LangChain + DeepSeek
â”‚   â”‚   â”œâ”€â”€ rag.py            # pipeline RAG completo
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â””â”€â”€ chat.py       # endpoint /chat
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ test_rag.py       # testes de retrieval
â”‚   â”‚   â””â”€â”€ test_chat.py      # testes de montagem de contexto
â”‚   â”œâ”€â”€ seed.py               # popula o banco com docs do petshop
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/       # componentes reutilizÃ¡veis
    â”‚   â”œâ”€â”€ sections/         # seÃ§Ãµes da pÃ¡gina
    â”‚   â”œâ”€â”€ services/         # chamadas API
    â”‚   â””â”€â”€ types/            # tipos TypeScript
    â”œâ”€â”€ package.json
    â””â”€â”€ vite.config.ts
```

## ğŸš€ Como Rodar

### Backend

1. **Clone o repositÃ³rio**
```bash
git clone <seu-repo>
cd chatbot-RAG/backend
```

2. **Crie um ambiente virtual**
```bash
python3 -m venv venv
source venv/bin/activate  # no Windows: venv\Scripts\activate
```

3. **Instale as dependÃªncias**
```bash
pip install -r requirements.txt
```

4. **Configure as variÃ¡veis de ambiente**
```bash
cp .env.example .env
# edite o .env e adicione sua OPENROUTER_API_KEY
# pegue uma chave em: https://openrouter.ai/keys
```

5. **Popule o banco de dados**
```bash
python seed.py
```

6. **Rode o servidor**
```bash
uvicorn app.main:app --reload
```

O backend estarÃ¡ rodando em `http://localhost:8000`

### Frontend

1. **Entre na pasta do frontend**
```bash
cd ../frontend
```

2. **Instale as dependÃªncias**
```bash
npm install
```

3. **Rode o servidor de desenvolvimento**
```bash
npm run dev
```

O frontend estarÃ¡ rodando em `http://localhost:5173`

## ğŸ§ª Testes

```bash
cd backend
pytest tests/ -v
```

**Cobertura:**
- Retrieval de documentos por similaridade
- ParÃ¢metro top_k
- Montagem de contexto
- Estrutura de resposta do RAG

## ğŸ“ Endpoints

### `POST /chat`

Envia uma pergunta e recebe uma resposta contextualizada.

**Request:**
```json
{
  "question": "Qual o horÃ¡rio de funcionamento?"
}
```

**Response:**
```json
{
  "answer": "O petshop funciona de segunda a sexta das 9h Ã s 19h...",
  "sources": ["HorÃ¡rio de Funcionamento", "ServiÃ§os"]
}
```

### `GET /health`

Verifica se o servidor estÃ¡ rodando.

**Response:**
```json
{
  "status": "ok"
}
```

## ğŸ¯ CaracterÃ­sticas

- âœ… RAG funcional com busca vetorial
- âœ… Embeddings locais (BGE-small)
- âœ… LLM integrado via LangChain
- âœ… Frontend React moderno e responsivo
- âœ… Testes com fixtures e mocks
- âœ… CÃ³digo limpo e bem estruturado
- âœ… API RESTful documentada

## ğŸ“¦ DependÃªncias Principais

**Backend:**
- `fastapi==0.115.6`
- `sqlalchemy==2.0.36`
- `sentence-transformers==3.3.1`
- `langchain==0.3.17`
- `pytest==7.4.4`

**Frontend:**
- `react==18.3.1`
- `typescript==5.6.2`
- `vite==6.0.3`

## ğŸ”§ PrÃ³ximas Melhorias Possiveis...

- [ ] Adicionar histÃ³rico de conversaÃ§Ã£o
- [ ] Implementar auto-scroll no chat
- [ ] Cache de embeddings
- [ ] Deploy em produÃ§Ã£o
- [ ] Mais testes de integraÃ§Ã£o

## ğŸ“„ LicenÃ§a

MIT

---

Feito com â¤ï¸ para demonstraÃ§Ã£o de RAG com FastAPI + React
